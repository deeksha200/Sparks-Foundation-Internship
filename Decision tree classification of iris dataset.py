# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wg3-Vj1ep5LZC4ak5WOKYenT6xgu275E

**DATA SCIENCE & BUSINESS ANALYTICS INTERN**

**THE SPARKS FOUNDATION**

**GRIP JULY 2021**

**NAME: DEEKSHA RAI**

**TASK 6: Prediction using Decision Tree 
Algorithm**

**Importing Necessary libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
print("imported")

dataset=pd.read_csv("/Iris.csv")
dataset.head()

"""**Numerical Columns**"""

num_col=list(dataset.select_dtypes(exclude='object').columns)
num_col

"""**Object Columns**"""

obj_col=list(dataset.select_dtypes(include='object').columns)
obj_col

"""**Checking For the Null Values**"""

dataset.isnull().sum()

"""**Univariate Analysis**"""

plt.figure(figsize=(10,5))
sns.countplot(dataset['Species'])
plt.title("Species Distribution")

"""1.   This shows the distribution of different classes as per their count
2.   According to this all classes are equal in count

**SepalLengthCm**
"""

dataset['SepalLengthCm'].plot(kind='density',title="SepalLengthCm")

sns.histplot(dataset['SepalLengthCm'])

"""**SepalWidthCm**"""

dataset['SepalWidthCm'].plot(kind='density',title="SepalWidthCm")

sns.histplot(dataset['SepalWidthCm'])

"""**PetalLengthCm**"""

dataset['PetalLengthCm'].plot(kind='density',title="PetalLengthCm")

sns.histplot(dataset['PetalLengthCm'])

"""**PetalWidthCm**"""

dataset['PetalWidthCm'].plot(kind='density',title="PetalWidthCm")

sns.histplot(dataset['PetalWidthCm'])

"""**Boxplot to check Outliers**"""

plt.figure(figsize=(10,5))
sns.boxplot(data=dataset.iloc[:,1:],orient="h")

""" **Bivariate
Analysis**
"""

sns.kdeplot(data=dataset,x='SepalLengthCm',hue='Species',fill=True)

sns.kdeplot(data=dataset,x='SepalWidthCm',hue='Species',fill=True)

sns.kdeplot(data=dataset,x='PetalLengthCm',hue='Species',fill=True)

sns.kdeplot(data=dataset,x='PetalWidthCm',hue='Species',fill=True)

sns.pairplot(dataset.drop("Id", axis=1), hue="Species", size=3, diag_kind="kde")

"""**Feature Scaling**"""

target=dataset['Species']
dataset.drop(['Species','Id'],inplace=True,axis=1)

from sklearn import preprocessing
scaler = preprocessing.RobustScaler()
robust_df = scaler.fit_transform(dataset)
robust_df = pd.DataFrame(robust_df, columns =['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm'])
robust_df

"""**Model Building**"""

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(dataset,target,test_size=0.3,random_state=42)

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import accuracy_score
from sklearn.model_selection import GridSearchCV

"""**Decision Tree Classifier**"""

model=DecisionTreeClassifier()
model.fit(x_train,y_train)
pred=model.predict(x_test)
print(accuracy_score(y_test,pred))

"""**Hyperparametric Tuning**"""

grid_param = {
    'criterion' : ['gini', 'entropy'],
    'max_depth' : [3, 5, 7, 10],
    'splitter' : ['best', 'random'],
    'min_samples_leaf' : [1, 2, 3, 5, 7],
    'min_samples_split' : [1, 2, 3, 5, 7],
    'max_features' : ['auto', 'sqrt', 'log2'],
}

decision = GridSearchCV(model, grid_param, cv = 5, n_jobs = -1, verbose = 1)
decision.fit(x_train, y_train)
print(decision.best_params_)
print(decision.best_score_)

"""**Building The Model With Best Params**"""

decision_tree = DecisionTreeClassifier(criterion='gini',
                                      max_depth=7,
                                      splitter='best',
                                      min_samples_leaf=2,
                                      min_samples_split=2,
                                      max_features='auto',
                                       random_state=42)
decision_tree.fit(x_train, y_train)
pred_new = decision_tree.predict(x_test)
print('Decision Tree model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, pred_new)))

from sklearn import tree
features=['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']
classes=['Iris-setosa','Iris-versicolor','Iris-virginica']
fig,axes=plt.subplots(nrows=1,ncols=1,figsize=(3,4),dpi=340)
tree.plot_tree(decision_tree,feature_names=features,class_names=classes,filled=True)

"""**Checking The model prediction on the outside data**"""

decision_tree.predict([[6, 3, 4, 2]])

